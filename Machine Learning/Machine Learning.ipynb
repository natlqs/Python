{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# 3 线性回归模型\n",
    "## 3.1 一元线性回归\n",
=======
    "## 线性回归模型\n",
>>>>>>> e411d09e7107566bfcc535eb4bced3626aa98081
    "### 3.1.2 一元线性回归的代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.绘制散点图"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
>>>>>>> e411d09e7107566bfcc535eb4bced3626aa98081
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = [[1], [2], [4], [5]]\n",
    "y = [2, 4, 6, 8]\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.引入Scikit-Learn库搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression # 引入线性回归的相关模块LinearRegression\n",
    "regr = LinearRegression()       # 构造一个初始的线性回归模型并命名为regr\n",
    "regr.fit(x, y)      # 用fit()函数完成模型搭建，此时的regr就是一个搭建好的线性回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.模型预测"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9]\n",
      "[2.9 4.3 7.1]\n"
     ]
    }
   ],
>>>>>>> e411d09e7107566bfcc535eb4bced3626aa98081
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "x = [[1], [2], [4], [5]]\n",
    "y  = [2, 4, 6, 8]\n",
    "regr = LinearRegression()\n",
    "regr.fit(x, y)\n",
    "y = regr.predict([[1.5]])   # 假设自变量是1.5，使用predict()函数就能预测对应的因变量y\n",
    "print(y)\n",
    "z = regr.predict([[1.5], [2.5], [4.5]])     # 预测多个自变量\n",
    "print(z)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.模型可视化"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeKklEQVR4nO3dd3xV9f3H8ddXQAhhyZQVNmEpKyBq6wacQGsHWutqS7etttjSElDQqqV1Vy21VlvraC2Gvdx7MBSSkDDCTBhhJEDIvPfz++Ne/GEM5l64N/fc3Pfz8eDhzb2HnI9fct8czj33vp2ZISIi3nVKrAcQEZEvp6AWEfE4BbWIiMcpqEVEPE5BLSLicQ2j8U3btm1r3bt3j8a3FhGpl1auXLnXzNrV9FhUgrp79+6sWLEiGt9aRKRecs5tPd5jOvUhIuJxCmoREY9TUIuIeJyCWkTE4xTUIiIeF9JVH865W4HvAwasBW4ys7JoDiYiEi8yVucza2kuBUWldGqVxOSxqUwY2jli37/WI2rnXGfgFiDNzAYBDYCJEZtARCSOZazOZ8qcteQXlWJAflEpU+asJWN1fsT2Eeqpj4ZAknOuIdAUKIjYBCIicWzW0lxKK32fu6+00sespbkR20etQW1m+cCfgG3ATqDYzJZV3845N8k5t8I5t6KwsDBiA4qIeFlBUWlY95+IUE59nAaMB3oAnYBk59x11bczs9lmlmZmae3a1fguSBGReqdTq6Sw7j8RoZz6uATYbGaFZlYJzAHOidgEIiJxbPLYVJIaNfjcfUmNGjB5bGrE9hHKVR/bgFHOuaZAKXAxoA/yEBGBz67uiOZVH7UGtZl96Jx7CVgFVAGrgdkRm0BEJM5NGNo5osFcXUjXUZvZdGB61KYQEakHSsqrSG4c+Q8l1TsTRURO0u6DZfz8+dVc/fh7VPn8Ef/+Ufk8ahGRRFDl8/PM+1t5YPl6Knx+fnx+L3xmEQ9WBbWIyAlYsWU/UzMyydl1iPP7tuPOcQPp3jY5KvtSUIuIhGHv4XLuXZzDSyt30KllE564bhhjB56Ocy5q+1RQi4iEwOc3nvtoG7OW5HCkwsePzu/FLRf3pump0Y9RBbWISC3W7ChiakYma3YUc3bPNsycMJDe7ZvX2f4V1CIix1F0pIJZS3N57qNttG3WmIcmDmHc4E5RPc1REwW1iEg1fr/x0qod3Ls4h6IjFdx4TnduHd2XFk0axWQeBbWIyDHW7TxIekYmK7YeYHi305g5/iwGdGoR05kU1CIiwKGySh5YvoFn3t9Cy6RG/PHqM/nG8C6cckrdnuaoiYJaRBKamTHv0wLuXriOwsPlXDMyhdvHptKq6amxHu0zCmoRSVgb9xxi2tws3tu0jzM6t+Rv16cxuGurWI/1BQpqEUk4RyqqeOS1jTz5dh5JjRowc8Igrh2ZQgMPnOaoiYJaRBKGmbE0azczF2STX1TK1cO6MOXyfrRt1jjWo30pBbWIJISt+0qYPi+LN3IL6Xd6c/77o7MZ0b11rMcKiYJaROq1skofT7y5icfe2ESjUxxTr+jPDed0p1GD+PmUZwW1iNRbr+fu4Y55WWzdd4Qrz+zI1CsGcHrLJrEeK2wKahGpd/KLSpkxP4ulWbvp2S6Zf3//LM7t3TbWY50wBbWI1BsVVX6efCePR17diGFMHpvK97/ag8YNG9T+mz1MQS0i9cJ7m/aSnpHJpsISxgzoQPqVA+jaummsx4oIBbWIxLU9B8u4a+E65n1aQNfWSTx1YxoX9esQ67EiSkEtInGpyufnn+9v5f7l66mo8nPLxX34yQW9aNIovk9z1ERBLSJxZ+XW/UzNyGLdzoNR7yv0AgW1iMSNfcG+wv+u3EHHOuor9IJag9o5lwq8eMxdPYFpZvZgtIYSETmWz2+88PE2/rgkl5LyKn54fk9uuagPyY0T41iz1v9LM8sFhgA45xoA+cDL0R1LRCRgzY4i0jMy+XRHMaN6tmbm+EH06VB3fYVeEO5fRxcDm8xsazSGERE5qvhIJbOW5fDvD7fRJjl2fYVeEG5QTwSer+kB59wkYBJASkrKSY4lIonKzPjfqnzuWbSOA0cquOHs7tw2JnZ9hV7gzCy0DZ07FSgABprZ7i/bNi0tzVasWBGB8UQkkazbeZBpczP5eMsBhqW0YuaEQQzs1DLWY9UJ59xKM0ur6bFwjqgvA1bVFtIiIuE6VFbJg69s4On3ttCiSUNP9RV6QThBfQ3HOe0hInIizIz5a3Zy14Lsz/oKJ49J5bRk7/QVekFIQe2cSwZGAz+M7jgikig27jnM9HmZvLtxH4M6t2D29WkM8WBfoReEFNRmVgK0ifIsIpIAjlRU8ehrG/nb23k0adSAmeMHcu1Z3TzbV+gFiXG1uIjEnJmxLHs3M+bHV1+hFyioRSTqtu07wh3zs3gtZw+pHZrznx+ezcge8dFX6AUKahGJmrJKH399M4/H3thIwzjtK/QCBbWIRMUbuXuYXg/6Cr1AQS0iEVVQVMqM+dksydpFz3bJPPu9s/hKn/jtK/QCBbWIRERFlZ+n3t3Mw69uwG/1p6/QCxTUInLS3t+0j/S5mWzcc5jRAzowrR71FXqBglpETtieg2XcvWgdcz+pv32FXqCgFpGwHe0rfGD5esqr/NxyUW9+cmHvetlX6AUKahEJy8qtB5iakcm6nQc5L9hX2KMe9xV6gYJaREKyv6SCexev4z8rAn2Fj39nGJcOqv99hV6goBaRL+X3G88f21d4Xk9uuThx+gq9QCstIse1dkcxU+dm8un2Is7q0ZqZEwbRN8H6Cr1AQS0iX1B8pJI/Lcvl2Q+30ia5MQ9+ewjjhyRmX6EXKKhF5DPqK/QmBbWIAJCz6yDpGYG+wqEprXjm5pEM6pwYfYVep6AWSXCHy6t4cPl6/hHsK7zv6jP45vCu6iv0EAW1SIIyMxas2cldC7PZc6iciSNSuH2s+gq9SEEtkoA2FR5m+tws3tm4l0GdW/DEdcMZmnJarMeS41BQiySQ0gofj76+gdlvBfoKZ4wfyHfUV+h5CmqRBLE8ezd3zMsiv6iUrw/rzJTL+tOuufoK44GCWqSe27bvCHfOz+LVYF/hi5NGcVbPNrEeS8KgoBapp8oqfcx+K4+/vB7oK/z95f258Vz1FcYjBbVIPfTm+kKmz81ky74jXHFmR9LVVxjXQgpq51wr4ElgEGDAzWb2fhTnEpETUFBUyswF2SzO3EXPtsn863sj+WqfdmF/n4zV+cxamktBUSmdWiUxeWwqE4Z2jsLEEopQj6gfApaY2Tecc6cC6tgR8ZBKn5+n3tnMQxHoK8xYnc+UOWsprfQBkF9UypQ5awEU1jFSa1A751oC5wE3AphZBVAR3bFEJFQf5O0jPSOTDXsOc0n/Dky/6uT6Cmctzf0spI8qrfQxa2mugjpGQjmi7gEUAv9wzg0GVgK/MLOSYzdyzk0CJgGkpKREek4RqWbPoTL+sHAdGZ8U0OW0JP5+QxoX9z/5vsKCotKw7pfoC+Xl34bAMOBxMxsKlAC/rb6Rmc02szQzS2vXLvxzYiISmiqfn6ff3czFf3qTRWt3cctFvXnltvMjEtIAnVolhXW/RF8oQb0D2GFmHwa/folAcItIHVu17QDjHn2XO+ZnMySlFUtvPY/bxqRGtFR28thUkqp9v6RGDZg8NjVi+5Dw1Hrqw8x2Oee2O+dSzSwXuBjIjv5oInLU/pIK7lucw4srtnN6iyY89p1hXBalvsKj56F11Yd3hHrVx8+Bfwev+MgDboreSCJylN9vvPDxdv64NIfDZXXXVzhhaGcFs4eE9KdtZp8AadEdRUSOlZlfzNSMTD7ZXsTIHq25S32FCUvvTBTxmOLSSv68LJdnP9hK6+TGPPDtwUwY0ll9hQlMQS3iEWbGnFX53LN4HftLKrj+7O7cOrovLZPUV5joFNQiHpC76xDpczP5aPN+hnRtxdM3qa9Q/p+CWiSGDpdX8dAr63nq3UBf4b1fP4NvpamvUD5PQS0SA2bGwrU7mbkgm90Hy7lmZFduH9tPfYVSIwW1SB3LKzzM9HlZvL1hLwM7teDx64YzTH2F8iUU1CJ1pLTCx19e38jst/Jo3OgU7hw3kOtGqa9QaqegFqkDn+srHNqZKZerr1BCp6AWiaLt+49wx7xAX2HfDs3UVygnREEtEgXlVT5mv5nHo69vpMEpjt9d3o+bzu2hvkI5IQpqkQh7a30h0+dlsXlvCVec0ZGpV/anY0t9RKicOAW1SITsLA70FS5au4sebZP5580jOa+vPptdTp6CWuQkHdtX6PMbvx7Tlx+c1/OE+gpFaqKgFjkJH+TtY9rcTNbvPswl/dsz/aqBJ9VXKFITBbXICdhzqIx7FuXw8up8upyWxJPXp3HJgMhUYYlUp6AWCUOVz8+zH2zlz8vWU17l5+cX9eYnF/Qm6VSd5pDoUVCLhGjVtgNMfTmT7J0H+Wqfttw5biA92zWL9ViSABTUIrU4UFLBfUtyeOHjQF/hX64dxuVnRKevUKQmCmqR4/D7jRdXbOe+JYG+wknBvsJmUe4rFKlOP3EiNVBfoXiJglrkGMWlldy/LJd/fbCV1smncv+3BvO1oeorlNhSUIsQ+CD/l1fn84dFOewvKee7o7px25hU9RWKJyioJeF9sa9whPoKxVMU1JKwSsqreOjVDTz1zmaaNWnIPV8/g2+rr1A8KKSgds5tAQ4BPqDKzNKiOZRINJkZi9buYuaCbHYdLGPiiK7cfmk/WquvUDwqnCPqC81sb9QmEakD1fsKH7tumPoKxfN06kMSQmmFj8fe2Mhf38yjcUP1FUp8CTWoDVjmnDPgr2Y2u/oGzrlJwCSAlJSUyE0ocpJeyd7NHfOz2HGglK8N7cyUy/vRvnmTWI8lErJQg/orZpbvnGsPLHfO5ZjZW8duEAzv2QBpaWkW4TlFwrZ9/xHunJ/FK+v20Kd9M16YNIpR6iuUOBRSUJtZfvC/e5xzLwMjgbe+/HeJxEZ5lY+/vZXHI6+pr1Dqh1qD2jmXDJxiZoeCt8cAM6I+mcgJeHtDIdPnZpG3t4TLzzid9CsHqK9Q4l4oR9QdgJeDb6FtCDxnZkuiOpVImHYWl3LXgnUsXLuTHm2TeebmkZyvvkKpJ2oNajPLAwbXwSwiYav0+fnHu5t58JVAX+GvRvdl0vnqK5T6RZfnSdz6MG8f6cG+wov7teeOceorlPpJQS1xp/BQOfcsWsec1fl0bpXE365PY7T6CqUeU1BL3PD5jWc/2MqfluVSVunjZxf25qcXqq9Q6j8FtcSFVdsOkJ6RSVbBQb7Suy13jh9IL/UVSoJQUIunHSip4I9Lc3j+o+10aNGYR68dyhVndNQH+UtCUVCLJ/n9xn+CfYUHy6r4wVd78ItL+qqvUBKSfurFc7IKAn2Fq7cVMbJ7a2ZMGEi/01vEeiyRmFFQi2ccLKvk/mXr+ef7W2idfCp//uZgvj5MfYUiCmqJOTMj45N87l4Y6Cu8blQ3fqW+QpHPKKglptbvPkR6RiYfbt7PYPUVitRIQS0xUVJexcOvbuDvwb7CP3ztDCaOUF+hSE0U1FKnzIzFmYG+wp3FZXw7rSu/uUx9hSJfRkEtdWbz3hKmzc3k7Q17GdCxBY9eO4zh3dRXKFIbBbVEXVmlj8de38gTwb7C6VcN4LujutFQH+QvEhIFtUTVq+sCfYXb95cyYUgnfndFf/UVioRJQS1REegrzOaVdbvp074Zz/9gFGf3Ul+hyIlQUEtEHe0rfPT1jZziHFMuC/QVntpQpzlETpSCWiLmnQ17mTY3k7y9JVw2KNBX2KmV+gpFTpaCWk7aruIyZi7MZuGanXRv01R9hSIRpqCWE1bp8/P0u1t48JX1VPmN20b3ZdJ5PWnSSB/kLxJJCmo5IR9t3k96Ria5uw9xUb/23HHVQFLaqK9QJBoU1BKWwkPl3LN4HXNWBfoKZ393OKMHdNAn3IlEkYJaQuLzG//+cCuzlgb6Cn96YS9+dmEf9RWK1AEFtdRq9bYDpM/NJDNffYUisRByUDvnGgArgHwzuzJ6I0koMlbnM2tpLgVFpXRqlcTksalMGNo5ovsI9BXm8sLH22jfvDGPXDOUK89UX6FIXQvniPoXwDpAnUgxlrE6nylz1lJa6QMgv6iUKXPWAkQkrP1+478rt3Pv4kBf4ffO7cEvR6uvUCRWQnrmOee6AFcAdwO3RXUiqdWspbmfhfRRpZU+Zi3NPemgziooJj0jk1XbihjR/TRmThikvkKRGAv1EOlB4Hag+fE2cM5NAiYBpKSknPRgcnwFRaVh3R+KY/sKT2uqvkIRL6k1qJ1zVwJ7zGylc+6C421nZrOB2QBpaWkWqQHlizq1SiK/hlA+kbdrmxlzPyng7kXr2Hu4nOvO6savx6TSsqn6CkW8IpQj6nOBcc65y4EmQAvn3LNmdl10R5PjmTw29XPnqAGSGjVg8tjUsL7Pht2HSJ+byQd5gb7Cp24YwRld1Fco4jW1BrWZTQGmAASPqH+tkI6to+ehT/Sqj5LyKh5+bQN/f3szyY3VVyjidXoZP05NGNo57BcOzYwlmbuYEewr/FZaF35zaT/aNGscpSlFJBLCCmozewN4IyqTSFRt3lvC9HlZvLW+kP4dW/DotUMZ3q11rMcSkRDoiLqeK6v08dgbm3jijU2cqr5CkbikoK7HXsvZzfR5gb7C8UM68fvL+9O+hfoKReKNgroe2nEg0Fe4PHs3vds347kfnMU5vdrGeiwROUEK6nqkvMrHk29v5pHXNuBw/PayftysvkKRuKegrife2bCXafMyySsM9BVOvXIAndVXKFIvKKjj3K7iMu5amM2CNTvp1qYpT980ggtS28d6LBGJIAV1nKr0+XnmvS08sHw9lX7j1kv68sPz1VcoUh8pqOPQR5v3M21uJjm7DnFhajvuGDeQbm2SYz2WiESJgjqO7D1czj2Lcvjfqh10bpXEX787nDHqKxSp9xTUccDnN54L9hWWVvr4yQW9+NlFvWl6qv74RBKBnuke98n2ItIzMlmbX8y5vdtw57hB9G6vvkKRRKKg9qiiIxXctyTQV9iumfoKRRKZgtpj/H7jpZU7uHdJDsWlldx8bg9+eUkfmjfRB/mLJCoFtYdkFRQzbW4WK7ceYET305gxfhD9O6qvUCTRKag9oHpf4Z++OZir1VcoIkEK6hgyM+Z9WsBdCwN9hd85K4XJY/qpr1BEPkdBHSMbdh9i2tws3s/bx+AuLfn7DWmc2aVVrMcSEQ9SUNex6n2Fd39tEBNHpNBAfYUichwK6jpiZizN2sWM+dkUFJfxzeFd+O1l6isUkdopqOvAlmBf4ZvrC+l3enMevmYoad3VVygioVFQR9FnfYVvbuLUBqcw7coBXH+2+gpFJDwK6ih5PWcP0+dlsW3/EfUVishJUVBH2I4DR5gxP5tl2bvp1S6Z575/Fuf0Vl+hiJw4BXWEVFT5+dvbeZ/1Ff7m0n587yvqKxSRk1drUDvnmgBvAY2D279kZtOjPVg8eXfjXtLnBvoKLx14OulXqa9QRCInlCPqcuAiMzvsnGsEvOOcW2xmH0R5Ns/bfbCMuxauY/6nBXRr05R/3DSCC9VXKCIRVmtQm5kBh4NfNgr+smgO5XVVPj9Pv7eFB1/ZQIXPzy8v6cOPzu+lvkIRiYqQzlE75xoAK4HewF/M7MMatpkETAJISUmJ5Iye8vGW/aRnqK9QROpOSEFtZj5giHOuFfCyc26QmWVW22Y2MBsgLS2t3h1xq69QRGIlrKs+zKzIOfc6cCmQWdv29YHPbzz30TZmLcmhtNLHjy/oxc/VVygidSiUqz7aAZXBkE4CRgP3RX0yD/h0exHpczNZs6OYc3q1YcZ49RWKSN0L5bCwI/BM8Dz1KcB/zGxBdMeKraIjFfxxaS7PfxToK3z4mqFcpb5CEYmRUK76WAMMrYNZYs7vN15atYN7F6uvUES8Qydag7ILDpI+N5OVWw+Q1u00Zk5QX6GIeEPCB/WhskruX76eZ94L9BXO+saZXD2sC6fog/xFxCMSNqjVVygi8SIhg3rjnkOkZwT6Cs/s0pInr09jcNdWsR5LRKRGCRXURyqqePjVjTz5dh7JjRty14RBXDNSfYUi4m0JEdTqKxSReFbvg3rL3hLumJ/FG7nqKxSR+FRvg7qs0sfjb2zicfUVikicq5dBfWxf4bjBnfj9Ff3poL5CEYlT9Sqo1VcoIvVRvQjqiio/T76Tx8Ovqq9QROqfuA/q94J9hZsKSxg7sAPTrhqovkIRqVfiNqjVVygiiSLugrrK5+eZ97fywPL16isUkYQQV0G9Yst+pgb7Ci9Ibced6isUkQQQF0G993A59y7O4aWVO+jUsglPXDecsQPVVygiicHTQa2+QhERDwf1mh1FTM0I9BWe3bMNMycMpHf75rEeS0SkznkuqIuOVDBraS7PBfsKH5o4hHGDO+k0h4gkLM8EdfW+wpvO6cGto9VXKCLimaA+VF7FvYtz6NE2mZnjBzGgk/oKRUTAQ0HdMqkRc358Dimtm6qvUETkGJ4JaoDubXVNtIhIdfrUIhERj6v1iNo51xX4J9ABMGC2mT0U6UEyVucza2kuBUWldGqVxOSxqUwY2jnSuxERiTuhnPqoAn5lZqucc82Blc655WaWHakhMlbnM2XOWkorfQDkF5UyZc5aAIW1iCS8Wk99mNlOM1sVvH0IWAdEND1nLc39LKSPKq30MWtpbiR3IyISl8I6R+2c6w4MBT6s4bFJzrkVzrkVhYWFYQ1RUFQa1v0iIokk5KB2zjUD/gf80swOVn/czGabWZqZpbVr1y6sITod54P+j3e/iEgiCSmonXONCIT0v81sTqSHmDw2laRqnyed1KgBk8emRnpXIiJxJ5SrPhzwd2Cdmd0fjSGOvmCoqz5ERL4olKs+zgW+C6x1zn0SvO93ZrYokoNMGNpZwSwiUoNag9rM3gH0nm4RkRjROxNFRDxOQS0i4nEKahERj1NQi4h4nDOzyH9T5wqBrSf429sCeyM4TqRorvBorvBorvDUx7m6mVmN7xaMSlCfDOfcCjNLi/Uc1Wmu8Giu8Giu8CTaXDr1ISLicQpqERGP82JQz471AMehucKjucKjucKTUHN57hy1iIh8nhePqEVE5BgKahERj4tJUDvnnnLO7XHOZR7nceece9g5t9E5t8Y5N8wjc13gnCt2zn0S/DWtjubq6px73TmX7ZzLcs79ooZt6nzNQpyrztfMOdfEOfeRc+7T4Fx31rBNY+fci8H1+jDYXuSFuW50zhUes17fj/Zcx+y7gXNutXNuQQ2P1fl6hThXTNbLObfFObc2uM8VNTwe2eejmdX5L+A8YBiQeZzHLwcWE/jUvlHAhx6Z6wJgQQzWqyMwLHi7ObAeGBDrNQtxrjpfs+AaNAvebkSgOm5UtW1+AjwRvD0ReNEjc90IPFrXP2PBfd8GPFfTn1cs1ivEuWKyXsAWoO2XPB7R52NMjqjN7C1g/5dsMh74pwV8ALRyznX0wFwxYaEVDNf5moU4V50LrsHh4JeNgr+qv2o+HngmePsl4OJgSUas54oJ51wX4ArgyeNsUufrFeJcXhXR56NXz1F3BrYf8/UOPBAAQWcH/+m62Dk3sK53/iUFwzFdsy8rPiYGaxb85/InwB5guZkdd73MrAooBtp4YC6Aq4P/XH7JOdc12jMFPQjcDviP83hM1iuEuSA262XAMufcSufcpBoej+jz0atB7VWrCLwffzDwCJBRlzt3tRQMx0otc8VkzczMZ2ZDgC7ASOfcoLrYb21CmGs+0N3MzgSW8/9HsVHjnLsS2GNmK6O9r3CEOFedr1fQV8xsGHAZ8FPn3HnR3JlXgzofOPZvxi7B+2LKzA4e/aerBarIGjnn2tbFvl3tBcMxWbPa5orlmgX3WQS8Dlxa7aHP1ss51xBoCeyL9Vxmts/MyoNfPgkMr4NxzgXGOee2AC8AFznnnq22TSzWq9a5YrRemFl+8L97gJeBkdU2iejz0atBPQ+4PvjK6Sig2Mx2xnoo59zpR8/LOedGEli/qD+5g/usrWC4ztcslLlisWbOuXbOuVbB20nAaCCn2mbzgBuCt78BvGbBV4FiOVe185jjCJz3jyozm2JmXcysO4EXCl8zs+uqbVbn6xXKXLFYL+dcsnOu+dHbwBig+pViEX0+hlJuG3HOuecJXA3Q1jm3A5hO4IUVzOwJYBGBV003AkeAmzwy1zeAHzvnqoBSYGK0f1iDaiwYBlKOmS0WaxbKXLFYs47AM865BgT+YviPmS1wzs0AVpjZPAJ/wfzLObeRwAvIE6M8U6hz3eKcGwdUBee6sQ7mqpEH1iuUuWKxXh2Al4PHHw2B58xsiXPuRxCd56PeQi4i4nFePfUhIiJBCmoREY9TUIuIeJyCWkTE4xTUIiIep6AWEfE4BbWIiMf9HxkRcYe/TXgLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
>>>>>>> e411d09e7107566bfcc535eb4bced3626aa98081
   "source": [
    "# 将搭建好的模型以可视化的形似展示出来\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = [[1], [2], [4], [5]]\n",
    "y  = [2, 4, 6, 8]\n",
    "regr = LinearRegression()\n",
    "regr.fit(x, y)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, regr.predict(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.线性回归方程构造"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系数a：1.4000000000000004\n",
      "截距b：0.7999999999999989\n"
     ]
    }
   ],
>>>>>>> e411d09e7107566bfcc535eb4bced3626aa98081
   "source": [
    "# 通过coef_和intercept_属性可以得到此时趋势线的系数和截距\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = [[1], [2], [4], [5]]\n",
    "y  = [2, 4, 6, 8]\n",
    "regr = LinearRegression()\n",
    "regr.fit(x, y)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, regr.predict(x))\n",
    "plt.show()\n",
    "print('系数a：' + str(regr.coef_[0])) #因为通过regr.coef_获得的是一个列表，所以要通过regr.coef_[0]选取其中的元素，\n",
    "# 又因为该元素为数字，所以进行字符串拼接时需要利用str()函数将其转换成字符串，运行结果如下。\n",
    "print('截距b：' + str(regr.intercept_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，拟合得到的一元线性回归方程为y = 1.4x + 0.8"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 案例实战：不同行业工龄与薪水的线性回归模型\n",
    "#### 1 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('IT行业收入表.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  工龄为自变量，薪水为因变量，散点图： \n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "df = pd.read_excel('IT行业收入表.xlsx')\n",
    "x = df[['工龄']]\n",
    "y = df['薪水']\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 用来正常显示中文标签\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('工龄')\n",
    "plt.ylabel('薪水')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "df = pd.read_excel('IT行业收入表.xlsx')\n",
    "x = df[[['工龄']]]\n",
    "y = df['薪水']\n",
    "regr = LinearRegression()\n",
    "regr.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "df = pd.read_excel('IT行业收入表.xlsx')\n",
    "x = df[['工龄']]\n",
    "y = df['薪水']\n",
    "regr = LinearRegression()\n",
    "regr.fit(x, y)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, regr.predict(x), color = 'red')     # color='red'表示用红色绘制趋势线\n",
    "plt.xlabel('工龄')\n",
    "plt.ylabel('薪水')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 线性回归方程构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "df = pd.read_excel('IT行业收入表.xlsx')\n",
    "x = df[['工龄']]\n",
    "y = df['薪水']\n",
    "regr = LinearRegression()\n",
    "regr.fit(x, y)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, regr.predict(x), color = 'red')     # color='red'表示用红色绘制趋势线\n",
    "plt.xlabel('工龄')\n",
    "plt.ylabel('薪水')\n",
    "plt.show()\n",
    "print('系数a:' + str(regr.coef_[0]))\n",
    "print('截距b:' + str(regr.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此拟合得到的医院线性回归方程为y = 2497x + 10143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 一元多次线性回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一元线性回归模型其实还有一个进阶版本——一元多次线性回归模型，比较常见的是一元二次线性回归模型，其形式可以表示为如下所示的公式。\n",
    "\n",
    "y＝ax^2＋bx＋c\n",
    "\n",
    "之所以还需要研究一元多次线性回归模型，是因为有时真正契合的趋势线可能不是一条直线，而是一条曲线。如右图所示，根据一元二次线性回归模型绘制的曲线更契合散点图呈现的数据变化趋势。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures    # 引入用于增加一个多次项内容的模块PolynomialFeatures\n",
    "from matplotlib import pyplot as plt\n",
    "df = pd.read_excel('IT行业收入表.xlsx')\n",
    "x = df[['工龄']]\n",
    "y = df['薪水']\n",
    "regr = LinearRegression()\n",
    "poly_reg = PolynomialFeatures(degree=2)     # 设置最高次项为2次项\n",
    "x_ = poly_reg.fit_transform(x)      # 将原有的x转换为一个新的二维数组x_，该二维数组包含新生成的二次项数据（x^2)和原有的一次项数据(x)\n",
    "regr.fit(x_, y)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, regr.predict(x_), color = 'red')\n",
    "# print(x_)\n",
    "# print(x)\n",
    "print(regr.coef_)   # 获取系数a, b\n",
    "print(regr.intercept_) # 获取常数项c\n",
    "# y1 = regr.predict([[1.,  9 , 81]])        # 预测9年工龄的工资\n",
    "# print(y1)         # 预测9年工龄的工资"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures    # 引入用于增加一个多次项内容的模块PolynomialFeatures\n",
    "from matplotlib import pyplot as plt\n",
    "df = pd.read_excel('金融行业收入表.xlsx')\n",
    "x = df[['工龄']]\n",
    "y = df['薪水']\n",
    "regr = LinearRegression()\n",
    "poly_reg = PolynomialFeatures(degree=2)     # 设置最高次项为2次项\n",
    "x_ = poly_reg.fit_transform(x)      # 将原有的x转换为一个新的二维数组x_，该二维数组包含新生成的二次项数据（x^2)和原有的一次项数据(x)\n",
    "regr.fit(x_, y)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, regr.predict(x_), color = 'red')\n",
    "plt.title('金融行业收入表')\n",
    "# print(x_)\n",
    "# print(x)\n",
    "print(regr.coef_)   # 获取系数a, b\n",
    "print(regr.intercept_) # 获取常数项c\n",
    "# y1 = regr.predict([[1.,  9 , 81]])        # 预测9年工龄的工资\n",
    "# print(y1)         # 预测9年工龄的工资"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures    # 引入用于增加一个多次项内容的模块PolynomialFeatures\n",
    "from matplotlib import pyplot as plt\n",
    "df = pd.read_excel('餐饮服务行业收入表.xlsx')\n",
    "x = df[['工龄']]\n",
    "y = df['薪水']\n",
    "regr = LinearRegression()\n",
    "poly_reg = PolynomialFeatures(degree=2)     # 设置最高次项为2次项\n",
    "x_ = poly_reg.fit_transform(x)      # 将原有的x转换为一个新的二维数组x_，该二维数组包含新生成的二次项数据（x^2)和原有的一次项数据(x)\n",
    "regr.fit(x_, y)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, regr.predict(x_), color = 'red')\n",
    "plt.title('金融行业收入表')\n",
    "# print(x_)\n",
    "# print(x)\n",
    "print(regr.coef_)   # 获取系数a, b\n",
    "print(regr.intercept_) # 获取常数项c\n",
    "# y1 = regr.predict([[1.,  9 , 81]])        # 预测9年工龄的工资\n",
    "# print(y1)         # 预测9年工龄的工资"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures    # 引入用于增加一个多次项内容的模块PolynomialFeatures\n",
    "from matplotlib import pyplot as plt\n",
    "df = pd.read_excel('汽车制造行业收入表.xlsx')\n",
    "x = df[['工龄']]\n",
    "y = df['薪水']\n",
    "regr = LinearRegression()\n",
    "poly_reg = PolynomialFeatures(degree=2)     # 设置最高次项为2次项\n",
    "x_ = poly_reg.fit_transform(x)      # 将原有的x转换为一个新的二维数组x_，该二维数组包含新生成的二次项数据（x^2)和原有的一次项数据(x)\n",
    "regr.fit(x_, y)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, regr.predict(x_), color = 'red')\n",
    "plt.title('金融行业收入表')\n",
    "# print(x_)\n",
    "# print(x)\n",
    "print(regr.coef_)   # 获取系数a, b\n",
    "print(regr.intercept_) # 获取常数项c\n",
    "# y1 = regr.predict([[1.,  9 , 81]])        # 预测9年工龄的工资\n",
    "# print(y1)         # 预测9年工龄的工资"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures    # 引入用于增加一个多次项内容的模块PolynomialFeatures\n",
    "from matplotlib import pyplot as plt\n",
    "files = ['IT行业收入表.xlsx', '金融行业收入表.xlsx', '汽车制造行业收入表.xlsx', '餐饮服务行业收入表.xlsx']\n",
    "for i in files:\n",
    "    df = pd.read_excel(i)\n",
    "    x = df[['工龄']]\n",
    "    y = df['薪水']\n",
    "    poly_reg = PolynomialFeatures(degree=2)     # 设置最高次项为2次项\n",
    "    x_ = poly_reg.fit_transform(x)      # 将原有的x转换为一个新的二维数组x_，该二维数组包含新生成的二次项数据（x^2)和原有的一次项数据(x)\n",
    "    regr.fit(x_, y)\n",
    "\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(x, regr.predict(x_))\n",
    "    plt.title('金融行业收入表')\n",
    "    # print(x_)\n",
    "    # print(x)\n",
    "    print(regr.coef_)   # 获取系数a, b\n",
    "    print(regr.intercept_) # 获取常数项c\n",
    "    # y1 = regr.predict([[1.,  9 , 81]])        # 预测9年工龄的工资\n",
    "    # print(y1)         # 预测9年工龄的工资"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 线性回归模型评估\n",
    "### 3.2.1 模型评估的编程实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型搭建完成后，还需要对模型进行评估，这里主要以3个值作为评判标准：R-squared（即统计学中的R2）、Adj.R-squared（即Adjusted R2）、P值。其中R-squared和Adj.R-squared用来衡量线性拟合的优劣，P值用来衡量特征变量的显著性。   \n",
    "在实战应用中，我们只需要记住这两条规则：R-squared和Adj.R-squared的取值范围为0～1，它们的值越接近1，则模型的拟合程度越高；P值在本质上是个概率值，其取值范围也为0～1，P值越接近0，则特征变量的显著性越高，即该特征变量真的和目标变量具有相关性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一元一次线性回归模型的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一元一次线性回归模型的评估\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot as plt\n",
    "df = pd.read_excel('IT行业收入表.xlsx')\n",
    "x = df[['工龄']]\n",
    "y = df['薪水']\n",
    "regr = LinearRegression()\n",
    "regr.fit(x, y)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, regr.predict(x), color = 'red')\n",
    "# print(x_)\n",
    "# print(x)\n",
    "print(regr.coef_)   # 获取系数a, b\n",
    "print(regr.intercept_) # 获取常数项c\n",
    "# y1 = regr.predict([[1.,  9 , 81]])        # 预测9年工龄的工资\n",
    "# print(y1)         # 预测9年工龄的工资\n",
    "\n",
    "\n",
    "import statsmodels.api as sm    # 引入用于评估线性回归模型的statsmodels\n",
    "x2 = sm.add_constant(x)     # 用add_constant()函数给原来的特征变量x添加常数项，并赋值给x2，这样才有y=ax + b中的常数项，即截距b\n",
    "est = sm.OLS(y, x2).fit()   # 用OLS()和fit()函数对y和x2进行线性回归方程搭建\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图中左下角的coef就是常数项（const）和特征变量（工龄）前的系数，即截距b和斜率系数a，可以看到和之前求得的结果是一致的。      \n",
    "对于模型评估而言，通常需要关心上图中的R-squared、Adj.R-squared和P值信息。这里的R-squared为0.855，Adj.R-squared为0.854，说明模型的线性拟合程度较高；这里的P值有两个，常数项（const）和特征变量（工龄）的P值都约等于0，所以这两个变量都和目标变量（薪水）显著相关，即真的具有相关性，而不是由偶然因素导致的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一元二次线性回归模型的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一元二次线性回归模型的评估\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('IT行业收入表.xlsx')\n",
    "x = df[['工龄']]\n",
    "y = df['薪水']\n",
    "regr = LinearRegression()\n",
    "poly_reg = PolynomialFeatures(degree=2)     # 设置最高次项为2次项\n",
    "x_ = poly_reg.fit_transform(x)      # 将原有的x转换为一个新的二维数组x_，该二维数组包含新生成的二次项数据（x^2)和原有的一次项数据(x)\n",
    "regr.fit(x_, y)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, regr.predict(x_), color = 'red')\n",
    "plt.title('金融行业收入表')\n",
    "\n",
    "import statsmodels.api as sm\n",
    "x2 = sm.add_constant(x_)    # 这里传入的是含有二次项（x^2)的x_\n",
    "est = sm.OLS(y, x2).fit()\n",
    "print(est.summary())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 多元线性回归\n",
    "### 3.3.1 多元线性回归的数学原理和代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 案例实战：客户价值预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm   # 引入线性回归模型评估相关库\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.read_excel('客户价值数据表.xlsx')\n",
    "x = df[['历史贷款金额', '贷款次数', '学历', '月收入', '性别']]\n",
    "y = df['客户价值']\n",
    "regr = LinearRegression()\n",
    "regr.fit(x, y)\n",
    "print('各系数:' + str(regr.coef_))\n",
    "print('常数项k0:' + str(regr.intercept_))\n",
    "x2 = sm.add_constant(x)\n",
    "est = sm.OLS(y, x2).fit()\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 逻辑回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归模型虽然名字中有回归两字，其本质却是分类模型。\n",
    "\n",
    "分类模型与回归模型的区别在于其预测的变量不是连续的，而是离散的一些类别，以最常见的二分类模型为例，分类模型可以预测一个人是否会违约、客户是否会流失、肿瘤是属于良性肿瘤还是恶性肿瘤等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 逻辑回归模型算法原理\n",
    "### 4.1.1 逻辑回归模型的数学原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归模型的算法原理中同样涉及了之前线性回归模型中学习到的线性回归方程：\n",
    "\n",
    "𝑦=𝑘_0+𝑘_1 𝑥_1+𝑘_2 𝑥_2+…+𝑘_𝑛 𝑥_𝑛\n",
    "\n",
    "上面这个方程是预测连续变量的，其取值范围属为负无穷到正无穷，而逻辑回归模型是用来预测类别的，比如它预测某物品是属于A类还是B类，它本质预测的是属于A类或者B类的概率，而概率的取值范围是0-1，因此我们不能直接用线性回归方程来预测概率。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要到用到下图所示的Sigmoid函数，该函数可以将取值为（-∞, +∞）的数转换到(0,1)之间，例如倘若y=3，那个通过Sigmoid函数转换后，f(y)就变成了1/(1+e^-3)=0.95了，这就可以作为一个概率值使用了。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-6, 6)  # 通过linspace()函数生成-6到6的等差数列，默认50个数\n",
    "y = 1.0 / (1.0 + np.exp(-x))    # Sigmoid函数计算公式，exp()函数表示指数函数\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 逻辑回归模型的代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression # 导入逻辑回归模型\n",
    "x = [[1, 0], [5, 1], [6, 4], [4, 2], [3, 2]]\n",
    "y = [0, 1, 1, 0, 0]\n",
    "model = LogisticRegression()\n",
    "model.fit(x, y)     # 将已有的数据使用逻辑回归模型进行拟合，训练成模型\n",
    "print(model.predict([[2, 2]]))  # 训练完模型，就可以用模型predict()函数进行预测分类了\n",
    "print(model.predict([[1, 0], [5, 1], [6, 4], [4, 1], [3, 2]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 逻辑回归模型的输入理解\n",
    "逻辑回归模型的本质其实是预测概率，而不是直接预测是属于0或1具体的类别，那么通过如下代码就可以获取概率值：\n",
    "```python\n",
    "y_pred_proba = model.predict_proba(x)\n",
    "```\n",
    "可以直接将y_pred_proba打印出来，它是一个numpy格式的二维数组，也可以根据2.2.1节数组构造DataFrame的知识点，通过引入pandas库将其通过DataFrame的形式打印出来：\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "a = pd.DataFrame(y_pred_proba, columns=['分类为0的概率', '分类为1的概率'])\n",
    "\n",
    "```\n",
    "完整代码如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0 1 1 0 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>分类为0的概率</th>\n",
       "      <th>分类为1的概率</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973449</td>\n",
       "      <td>0.026551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390720</td>\n",
       "      <td>0.609280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.179910</td>\n",
       "      <td>0.820090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.631679</td>\n",
       "      <td>0.368321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.824245</td>\n",
       "      <td>0.175755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    分类为0的概率   分类为1的概率\n",
       "0  0.973449  0.026551\n",
       "1  0.390720  0.609280\n",
       "2  0.179910  0.820090\n",
       "3  0.631679  0.368321\n",
       "4  0.824245  0.175755"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression # 导入逻辑回归模型\n",
    "import pandas as pd\n",
    "\n",
    "x = [[1, 0], [5, 1], [6, 4], [4, 2], [3, 2]]\n",
    "y = [0, 1, 1, 0, 0]\n",
    "model = LogisticRegression()\n",
    "model.fit(x, y)     # 将已有的数据使用逻辑回归模型进行拟合，训练成模型\n",
    "y_pred_proba = model.predict_proba(x)\n",
    "print(model.predict([[2, 2]]))  # 训练完模型，就可以用模型predict()函数进行预测分类了\n",
    "print(model.predict([[1, 0], [5, 1], [6, 4], [4, 1], [3, 2]]))\n",
    "a = pd.DataFrame(y_pred_proba, columns=['分类为0的概率', '分类为1的概率'])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本案例中，因为每个数据是有两个特征变量，所以逻辑回归计算概率原理的本质就是下图所示的计算公式，注意在二分类模型（0和1两个分类）中，下面这个概率P值默认预测分类为1的概率。\n",
    "\n",
    "𝑃=1/(1+𝑒^(−(𝑘_0+𝑘_1 𝑥_1+𝑘_2 𝑥_2) )  )\n",
    "\n",
    "机器学习模型所需要确定就是其中的截距项k0和系数k1和k2，使得预测的概率尽可能准确，通过如下代码便可以获取机器计算出来的截距项k0和系数k1和k2, 结果如下，这里为了数据美观仅保留2位小数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0 1 1 0 0]\n",
      "[[1.00595248 0.02223835]]\n",
      "[-4.60771284]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression # 导入逻辑回归模型\n",
    "import pandas as pd\n",
    "\n",
    "x = [[1, 0], [5, 1], [6, 4], [4, 2], [3, 2]]\n",
    "y = [0, 1, 1, 0, 0]\n",
    "model = LogisticRegression()\n",
    "model.fit(x, y)     # 将已有的数据使用逻辑回归模型进行拟合，训练成模型\n",
    "y_pred_proba = model.predict_proba(x)\n",
    "print(model.predict([[2, 2]]))  # 训练完模型，就可以用模型predict()函数进行预测分类了\n",
    "print(model.predict([[1, 0], [5, 1], [6, 4], [4, 1], [3, 2]]))\n",
    "a = pd.DataFrame(y_pred_proba, columns=['分类为0的概率', '分类为1的概率'])\n",
    "a\n",
    "print(model.coef_)      # 系数k1与k2\n",
    "print(model.intercept_)     # 截距k0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想批量查看预测概率，可以通过如下代码进行批量运算，其中np.exp()用来进行指数运算（即e^x），np.dot()用来做数据点乘，即将系数和特征值一一相乘，model.coef_.T中的.T则是将数据进行转置。\n",
    "\n",
    "示例np.dot()和np.exp():\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0 1 1 0 0]\n",
      "[[1.00595248 0.02223835]]\n",
      "[-4.60771284]\n",
      "[0.02655146]\n",
      "[0.60928028]\n",
      "[0.82008972]\n",
      "[0.36832107]\n",
      "[0.17575473]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression # 导入逻辑回归模型\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x = [[1, 0], [5, 1], [6, 4], [4, 2], [3, 2]]\n",
    "y = [0, 1, 1, 0, 0]\n",
    "model = LogisticRegression()\n",
    "model.fit(x, y)     # 将已有的数据使用逻辑回归模型进行拟合，训练成模型\n",
    "y_pred_proba = model.predict_proba(x)\n",
    "print(model.predict([[2, 2]]))  # 训练完模型，就可以用模型predict()函数进行预测分类了\n",
    "print(model.predict([[1, 0], [5, 1], [6, 4], [4, 1], [3, 2]]))\n",
    "a = pd.DataFrame(y_pred_proba, columns=['分类为0的概率', '分类为1的概率'])\n",
    "a\n",
    "print(model.coef_)      # 系数k1与k2\n",
    "print(model.intercept_)     # 截距k0\n",
    "\n",
    "for i in range(5):\n",
    "    print(1 / (1 + np.exp(-(np.dot(x[i], model.coef_.T) + model.intercept_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归模型除了可以处理二分类问题外，还可以处理多分类问题，演示代码如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>分类为-1的概率</th>\n",
       "      <th>分类为0的概率</th>\n",
       "      <th>分类为1的概率</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.883523</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.093077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   分类为-1的概率  分类为0的概率   分类为1的概率\n",
       "0  0.883523   0.0234  0.093077"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "x = [[1, 0], [5, 1], [6, 4], [4, 2], [3, 2]]\n",
    "y = [-1, 0, 1, 1, 1]        # 这里有三个分类 -1， 0， 1\n",
    "\n",
    "model.fit(x, y)\n",
    "print(model.predict([[0, 0]]))\n",
    "y_pred_proba_1 = model.predict_proba([[0, 0]])\n",
    "b = pd.DataFrame(y_pred_proba_1, columns=['分类为-1的概率', '分类为0的概率', '分类为1的概率'])\n",
    "b\n",
    "print(model.coef_)      # 系数k1与k2\n",
    "print(model.intercept_)     # 截距项k0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 案例实战 - 股票客户流失预警模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7863733144073811\n",
      "0.7863733144073811\n",
      "[[0.57190754 0.42809246]\n",
      " [0.92230797 0.07769203]\n",
      " [0.8041344  0.1958656 ]\n",
      " ...\n",
      " [0.84186844 0.15813156]\n",
      " [0.65426352 0.34573648]\n",
      " [0.7913905  0.2086095 ]]\n",
      "      预测值  实际值\n",
      "0       0    0\n",
      "1       0    0\n",
      "2       0    0\n",
      "3       0    0\n",
      "4       0    0\n",
      "...   ...  ...\n",
      "1404    0    0\n",
      "1405    1    0\n",
      "1406    0    1\n",
      "1407    0    0\n",
      "1408    0    0\n",
      "\n",
      "[1409 rows x 2 columns]\n",
      "[[ 2.40953183e-05  8.07555497e-03  1.03704709e-02 -2.54427212e-03\n",
      "  -1.06196334e-04]]\n",
      "[-1.43130397e-06]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split        # 导入随机划分数据模块\n",
    "from sklearn.metrics import accuracy_score      # 预测准确度\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('股票客户流失.xlsx')\n",
    "x = df.drop(columns='是否流失')\n",
    "y = df['是否流失']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "a = pd.DataFrame()      # 创建一个空DataFrame\n",
    "a['预测值'] = list(y_pred)\n",
    "a['实际值'] = list(y_test)\n",
    "score = accuracy_score(y_pred, y_test)      # 打印预测准确度\n",
    "score1 = model.score(x_test, y_test) # 模型自带的score函数同样可以获得准确度评分\n",
    "y_pred_proba2 = model.predict_proba(x_test)\n",
    "b = pd.DataFrame(y_pred_proba2, columns=['不流失概率', '流失概率']) # 获取预测概率值\n",
    "print(score)\n",
    "print(score1)\n",
    "print(y_pred_proba2)\n",
    "print(a)\n",
    "b\n",
    "print(model.coef_)      # 系数ki\n",
    "print(model.intercept_)     # 截距项 k0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 模型评估方法 - ROC曲线与KS曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型搭建完成后，我们还需要对模型的优劣进行评估，对于二分类模型来说，主流的评估方法有ROC曲线和KS曲线两种方法，这里我们先主要讲解ROC曲线的基本原理，并用ROC曲线来评估上一小节搭建的股票客户流失预警模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0(预测不流失)  1(预测流失)\n",
      "0(实际不流失)       932       95\n",
      "1(实际流失)        220      162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86      1027\n",
      "           1       0.63      0.42      0.51       382\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.72      0.67      0.68      1409\n",
      "weighted avg       0.76      0.78      0.76      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split        # 导入随机划分数据模块\n",
    "from sklearn.metrics import accuracy_score      # 预测准确度\n",
    "from sklearn.metrics import confusion_matrix    # 导入混淆矩阵\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('股票客户流失.xlsx')\n",
    "x = df.drop(columns='是否流失')\n",
    "y = df['是否流失']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "a = pd.DataFrame()      # 创建一个空DataFrame\n",
    "a['预测值'] = list(y_pred)\n",
    "a['实际值'] = list(y_test)\n",
    "score = accuracy_score(y_pred, y_test)      # 打印预测准确度\n",
    "score1 = model.score(x_test, y_test) # 模型自带的score函数同样可以获得准确度评分\n",
    "y_pred_proba2 = model.predict_proba(x_test)\n",
    "b = pd.DataFrame(y_pred_proba2, columns=['不流失概率', '流失概率']) # 获取预测概率值\n",
    "m = confusion_matrix(y_test, y_pred)        # 传入预测值和真实值\n",
    "c = pd.DataFrame(m, index=['0(实际不流失)', '1(实际流失)'], columns=['0(预测不流失)', '1(预测流失)'])\n",
    "print(c)\n",
    "print(classification_report(y_test, y_pred))    # 传入预测值和真实值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 决策树模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 决策树模型的基本原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "x = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [1, 0, 0, 1, 1]\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "model.fit(x, y)\n",
    "print(model.predict([[5, 5]]))\n",
    "print(model.predict([[5,5], [7, 7], [9, 9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "x = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [1, 2, 3, 4, 5]\n",
    "model = DecisionTreeRegressor(max_depth=2, random_state=0)\n",
    "model.fit(x, y)\n",
    "print(model.predict([[9, 9]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 案例实战：员工离职预测模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      预测值  实际值\n",
      "0       0    0\n",
      "1       0    0\n",
      "2       1    1\n",
      "3       0    0\n",
      "4       0    0\n",
      "...   ...  ...\n",
      "2995    1    1\n",
      "2996    0    0\n",
      "2997    0    0\n",
      "2998    1    1\n",
      "2999    0    0\n",
      "\n",
      "[3000 rows x 2 columns]\n",
      "0.9573333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('员工离职预测模型.xlsx')\n",
    "df = df.replace({'工资': {'低': 0, '中': 1, '高': 2}})\n",
    "x = df.drop(columns='离职')\n",
    "y = df['离职']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123)\n",
    "model = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "d = pd.DataFrame()\n",
    "d['预测值'] = list(y_pred)\n",
    "d['实际值'] = list(y_test)\n",
    "print(d)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
=======
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "675868e700a09232ff5f9656c2a8569beabdbea23de5bdd2dccbb6bda2f05741"
  },
>>>>>>> e411d09e7107566bfcc535eb4bced3626aa98081
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
<<<<<<< HEAD
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c8ee1e197f4c1464fb5e19bba5b7903b5cfc0e5758f0e461a636e5335b08c52"
   }
  }
=======
  "orig_nbformat": 4
>>>>>>> e411d09e7107566bfcc535eb4bced3626aa98081
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
